{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e2c2d6",
   "metadata": {},
   "source": [
    "![Twitter Sentiment Analysis](tt4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52997b0",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "With the large amount of data generated by users on social networks, social network monitoring techniques have become increasingly relevant. In this context, natural language processing (NLP) techniques have become essential to extract relevant information from this unstructured data.\n",
    "\n",
    "This project aims to use NLP techniques to analyze sentiments in tweets using Gensim Word2Vec for text vectorization and the logistic regression algorithm from the sklearn library for sentiment classification into negative or positive.\n",
    "\n",
    "The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. It is capable of capturing semantic relationships between words, which allows for superior performance in classification.\n",
    "\n",
    "It is expected that the results obtained can contribute to the understanding of the sentiments expressed by Twitter users regarding certain topics and events.\n",
    "\n",
    "This project has been divided into three notebooks:<br>\n",
    "The first notebook concerns data visualization and cleaning.<br>\n",
    "The second notebook concerns training of the word2vec and logistic regression models.<br>\n",
    "The third notebook uses the previously trained models for classifying tweets extracted using the Twitter API and the tweepy library.\n",
    "\n",
    "***\n",
    "\n",
    "# Classificating tweets using Twitter API and Tweepy library\n",
    "\n",
    "## Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab60d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nltk\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import tweepy as tw\n",
    "import configparser\n",
    "from wordcloud import WordCloud\n",
    "from nltk import tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c7e37",
   "metadata": {},
   "source": [
    "## loading Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8608451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cbow = KeyedVectors.load(\"models/word2vec_cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480fd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sg = KeyedVectors.load(\"models/word2vec_sg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7b004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/lr_cbow.pkl\", \"rb\") as f:\n",
    "    lr_cbow = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a2b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/lr_sg.pkl\", \"rb\") as f:\n",
    "    lr_sg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2e322",
   "metadata": {},
   "source": [
    "## Defining functions to pre-process tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac65d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "ws_tokenizer = tokenize.WhitespaceTokenizer()\n",
    "punc_tokenizer = tokenize.WordPunctTokenizer()\n",
    "porter = PorterStemmer()\n",
    "punc_lst = [p for p in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cef2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords (tweet):\n",
    "    ntweet = list()\n",
    "    words = ws_tokenizer.tokenize(tweet)\n",
    "    for word in words:\n",
    "        if (word.lower() not in stop_words) and (word.lower().startswith(\"http\")==False) and (word.lower().startswith(\"&\")==False):\n",
    "            ntweet.append(word.lower())\n",
    "    return ' '.join(word for word in ntweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9346206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words2 = stop_words + punc_lst\n",
    "def remove_punctuation (tweet):\n",
    "    ntweet = list()\n",
    "    \n",
    "    words = punc_tokenizer.tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word not in stop_words2:\n",
    "            ntweet.append(word)\n",
    "    return ' '.join(word for word in ntweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36796d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words3 = [unidecode.unidecode(text) for text in stop_words2]\n",
    "def remove_accentuation (tweet):\n",
    "    tweet = unidecode.unidecode(tweet)\n",
    "    \n",
    "    ntweet = list()\n",
    "    words = punc_tokenizer.tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word not in stop_words3:\n",
    "            ntweet.append(word)\n",
    "    return ' '.join(word for word in ntweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "981baf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming (tweet):\n",
    "    ntweet = list()\n",
    "    words = punc_tokenizer.tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word not in stop_words3:\n",
    "            ntweet.append(porter.stem(word))\n",
    "    return ' '.join(word for word in ntweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6010c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_alpha(tweet):\n",
    "    ntweet = list()\n",
    "    words = ws_tokenizer.tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word.isalpha() and word!='quot':\n",
    "            ntweet.append(word)\n",
    "    return ' '.join(word for word in ntweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e72cd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = remove_stopwords(tweet)\n",
    "    tweet = remove_punctuation(tweet)\n",
    "    tweet = remove_accentuation(tweet)\n",
    "    tweet = stemming(tweet)\n",
    "    tweet = only_alpha(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10956c",
   "metadata": {},
   "source": [
    "### Creating function to vectorize tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4207e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize (tweet, model):\n",
    "    vector = np.zeros(300)\n",
    "    \n",
    "    words = ws_tokenizer.tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv.get_vector(word)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedb651",
   "metadata": {},
   "source": [
    "### Creating and testing predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d7ca973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tweet, vec_model, lr_model):\n",
    "    original_tweet = tweet\n",
    "    tweet = preprocess_tweet(tweet)\n",
    "    vector = vectorize(tweet, vec_model)\n",
    "    \n",
    "    result = lr_model.predict(vector.reshape(1, -1))\n",
    "    \n",
    "    if (result[0]==0):\n",
    "        sentiment = 'Negative'\n",
    "    \n",
    "    if (result[0]==1):\n",
    "        sentiment = 'Positive'\n",
    "        \n",
    "    return('\"' + original_tweet + '\" is a ' + sentiment + ' tweet.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f536571b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My dog died\" is a Negative tweet.\n",
      "\"I've found 10 bucks today\" is a Positive tweet.\n",
      "\"feeling tired\" is a Negative tweet.\n",
      "\"i can't wait for the weekend!!! it's gonna be awesome\" is a Positive tweet.\n",
      "\"i'm excited about college this year\" is a Positive tweet.\n",
      "\"I procrastinated a lot, the exams start next week and I don't know anything\" is a Negative tweet.\n",
      "\"I failed the test today\" is a Negative tweet.\n"
     ]
    }
   ],
   "source": [
    "tweet = \"My dog died\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))\n",
    "\n",
    "tweet = \"I've found 10 bucks today\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))\n",
    "\n",
    "tweet = \"feeling tired\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))\n",
    "\n",
    "tweet = \"i can't wait for the weekend!!! it's gonna be awesome\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))\n",
    "\n",
    "tweet = \"i'm excited about college this year\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))\n",
    "\n",
    "tweet = \"I procrastinated a lot, the exams start next week and I don't know anything\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))\n",
    "\n",
    "tweet = \"I failed the test today\"\n",
    "print(predict(tweet,w2v_cbow, lr_cbow))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e882aa",
   "metadata": {},
   "source": [
    "### Autenticating Twitter API and extracting tweets using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "737dc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \n",
    "api_secret = \n",
    "bearer_token = \n",
    "access_token = \n",
    "access_token_secret = \n",
    "client_id = \n",
    "client_secret = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61dc7ab5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@uptownsaul Well if it's dishonest then why is XRP available to buy on exchanges all over the world....it's only in the US that SOME of the exchanges delisted XRP..\\nIf it's not meant for retail then explain why I am able to buy $100k of XRP daily....\", \"@TransRightsSlay @jay59834501 @sloppyrl @MrAndyNgo @elonmusk I am exposed to compelled speech and pressured into participating in gender identity ideology against my own beliefs. That doesn't make me feel great at all? But you don't care about that, as long as the respect is all one way in your direction.\", '@bostongeorgeohh I have a pair of Armada invictus 89 but I am thinking of getting a wider ski for powder days out west and the rare east coast powder day.  Looking at the Ripstick 106. Either the black or non black.  Thoughts?', 'im still trying, struggling to recover everything inside and out. yes i am happy of what i am doing right now but this is what you wanted right? don‚Äôt play victim terpaling tersakiti when you‚Äôre the one who ends everything.', \"@TRUMPSBLONDE_23 @shannonazusa I'm very sorry to hear about this and I am praying for you!\", '@Limburble i don‚Äôt know why this didn‚Äôt notify me but i am glad you enjoy my new dogs', \"Deciding I'm going home at 7 no matter where I am on this\", '@Mad_RabbitBR I am honoured hearing that you like it that much ü§£\\nPlease, feel free to use it however you like. I‚Äôll keep it uncopyrighted specifically for you', '@YugenStudioss OMG i would love to learn more about this opportunity! I am a foodie and always open to trying amazing foods! https://t.co/XGmr2vj0Tm', '@oncloud_e I am not a libtard', \"@AusHumanRights @GuardianAus WE ARE ONE\\nBUT WE ARE MANY\\nAND FROM ALL THE LANDS ON EARTH WE COME\\nWE'LL SHARE A DREAM\\nAND SING WITH ONE VOICE\\nI AM , YOU ARE, WE ARE AUSTRALIAN.\", '@kellygoround good lord fuck them i am so sorry üò£', 'I am in bed watching golden girls üíõ', 'I am human and I need to be loved just like everybody else does', '@lyzl @KF_Crow I am hoping she grows up and runs for office. ‚ù§Ô∏è', '@MikeHudema I am not bombarded by any other faith based religions on my feed except this zealotry.', 'Do yall ever wonder what your overweight friends think about the comments you make about Zion‚Äôs body?\\n\\nWho am I kidding, yall don‚Äôt give a damn.', '@the_economystic @ZoidPay @kucoincom @binance Yes that message has been added this afternoon.\\nI received no rewards for 24 hours so asked on their telegram where I was told it had finished.\\nI later realised the info given was not correct.\\nWhich I am very glad to hear.. Sorry for the confusion.', 'am I the problem? ‚Ä¶. No I don‚Äôt think so it be y‚Äôall üò≠üò≠', '@fiwriino i am so sorry sarah. this was really tragic news. please know that you may be physically alone, but you are not alone. üíú', 'My baby will be one in 11 days‚Ä¶. I am unwell', 'Him from deliberate, meaning I am so tired\\nÿü?\\nŸÜŸÖÿ¥€í\\n\\nüîπH4üîπ\\nüîπH4üîπ\\nüîπH4üîπ', \"@richardursomd They want to focus on killing the over 60s. I am 71 and no vaccine for me. I had Omicron and have natural immunity. You couldn't pay me any amount to take ANY of their killer vaccines or boosters.\", '@domquixotedemi i for light am üò≠', 'I know it‚Äôs the eclipse but I am having fun being a lil shit disturber today. üòà', 'And i am ü§∑üèæ\\u200d‚ôÄÔ∏è https://t.co/GotiYuNyAn', '@UncleAbeMaybe @Douglovesribeye I am robot like with spices..automatically shaking away..hitting those chin thighs hard!!..lol.\\nMarco Polo was on to something with that Spice route deal he had! Life would suck without salt and pepper and spices. Eh?', '@s4toruu I AM BACKKKK IMY üò≠üíù', 'I am, but hopefully this new godzillaxkong film will adapt into a new monsterverse fighting game in the near future https://t.co/V6D2CwTCen', '@Rickee53 @DrJoLynneW That has been my plight for a very long time too, being disappointed over n over again.  I felt that God has forsaken me or i was just a failure. However, i am HUNGRY for God n  i need to go on another level with him... God sees your yearning sir,  n he is saying  LOOK AGAIN!', 'Knowing that i will never be able to 100% explain to someone how I think and why I am the way I am is so fucking draining.', 'Who am I? Working on my personal branding and his week. How am I doing? #shortvideo #adhd https://t.co/onoLqwRMcH', \"@LivePDDave1 I am thinking he has a half dozen steaks stored in those cheeks like a chipmunk storing seeds....he has more chins than a hong kong phonebook.....If you pumped his stomach, you'd find half the missing persons from NY.   Did I say all of that out loud?\", '@doggy_ebooks i am Marijuanas Steve', '@ramonaways @TulParentsVoice @bakerleft Help so proud of they. You have know idea just how proud of that I am. I was standing an Cheering that night. Saying take that you fucking liberals. It was awesome seeing all of you angry and screaming. It made it even sweeter. I will never forget it. What a birthday. Thanks', 'no offense to myself but wtf am i doing', 'I am happy to be wrong üò≠', '@BulkRaiser Thanks for giving us such a great opportunity. I am supporting it. always success for the development team To The Moon üöÄüöÄüöÄüåï\\n\\n@sultandua1 @Deriltoretto1 @Nadiaaaa445', \"Pftt, well in that sense of course I am.\\n\\n.. Yeah, I like to think so. I'm a little bit someone with everyone even if it's probably  ... unrecognizable, you know ? https://t.co/dlNEqEnsbL\", 'My daily #tarot - the #sun - this is a #joyful card, a sign of #positivity and #success it‚Äôs a time to acknowledge your blessings. I am definitely resonating with this card today. üåû https://t.co/cCCkiDdgax', '@am_d_blackangel @RealOlaudah Inventions create room for advancement with ease. E.g Google(largest search engine or a literal library) at your fingertips, Clouds(Massive storage capacity) and so on. Now with A.I, it‚Äôs about to be a whole different ball game.', 'I am so grateful to Gleb that I could not help but share my happiness with another person!  I decided to buy the work that I wanted to buy from @marveliri üòçüòç\\n\\nThis is incredible work üòç and I feel üåä theme https://t.co/GuIdMmQZNk', '@I_am_QDee Yeah bro. I just dey see the update. Let‚Äôs see how things unfolds.', '@GabrielisSus @ang3lz4y this is why i am going to buy them 3 things for our 7 months, spend money on the things u love', \"@hairydad555 I am flattered by the analogy! \\nBut we don't need to argue. However, we should always question authority respectfully (I'm still working on it too!)\", 'I‚Äôm proud to announce that I - Venusian Prince - did in fact study for his 10 am exam that he will be taking tomorrow. üòå https://t.co/7axPStvj5M', '@QueenOfDiagolon Pod bean, and listen in the truck first thing in the am, it gives me that jump start I need in the morning!', '@POTUS You are obviously affraid it will be used against you.....I love your support of the seond ammendment.....BTW, when they are banned, you will have no Milatary, but I am sure that does not concern you.  Why not just give more weapons to overseas countries, that will help solve it.', 'Who pro am team should I join ?', 'I have accepted the fact that I am not religious.\\nI have accepted the fact that I have much to learn.\\nI have accepted the fact that life fucks all.\\nI have accepted the fact that I am going to hell. \\nI have accepted the fact that people are the worst.', '@kxpture I am King üëë', '@kevinfolta The fact that you are wasting your time with me is very telling. I am a waste of your time.', 'Also wanna add I am sick and tired of the main characters knowing each other when they were little kids \\nLike STAPPHHüò≠', '@fixbun i am so sorry you have had to experience this you don‚Äôt deserve that invalidation from your mom i‚Äôm here if you need to talk or anything dms are always open.', '@CounselorBDavis Yes! I‚Äôm leaving at the end of the year and it is so bittersweet! I love my coworkers (and my kids) but I‚Äôm so burnt out I need a change. But I can‚Äôt even put into words how fortunate I am for these professionals. We are a team and I can‚Äôt imagine having a better one!', '@EuphoriTori I was reminded by associates that male conservatives find the mere notion of performing cunninlingus dehumanizing and like kinda gay, bro. So I retract my edgy joke. I am sorry if I offended.', '@nomacdonald @Terrilltf No, I am not.  You might want to give the Truth and (Re)Conciliation Report a squint.  Before you speak on the subject. I want to be proud of my country again but I can not yet because of racists and ignorance. https://t.co/QuAVX7Htcw', '(gentle poke if anyone is available to mix in like. the next few months maybe‚Ä¶‚Ä¶it‚Äôs a very short song but I am still sick so \\U0001fae1 it‚Äôll take a bit!)', 'I am so obsessed with this dog', '@calxvoid oh! hi mars i am alright how are you?', '\"I am Leaving, Take care of your Emaan\"üò¢üòî ~Ramadan', '@thefacedateapp This is the weirdest follow I have ever gotten. WTF.. I am down though. @BarterBlex @DojaCat Someday I will get that @DojaCat follow. At this point I am torn between what I want more. A retweet of like form @DojaCat or actually getting to eat that ass. Just Sayin.', 'I am online ‚ô•Ô∏è @Flirt4Free https://t.co/P1Nd7daB9C', 'Just got excited because I saw I had a Snapchat notification and it was fucking  My AI. Man I am so lonely.', '@04_kcjj Did you all watch the video. Those of you who are on the side of the student, not child? Really? She swung on the teacher first‚Ä¶ if she had a gun and shot someone she would be tried as an adult. So, her combativeness was tested and tried as an adult. See Exhibit A, case closed.', '@silverstreammlp I am, but I usually stay up all night', \"@racheledini1 Haha I am guilty of the rhetorical flourishes that make it seem like everything I write about is radical and world changing. But I recognize it's rhetorical BS!\", '@machtwotoaster I am so excited to see this finished, it already looks so good üò≠üò≠', '@PatrickBarclay4 @TaraOComics \"If the evil gods hear how happy I am with my gf, they will take her from me.\"', '@Angelo47596494 @hazzzzzmat @destopic_ @thecircusdragon @cycleofph @CipherGhostof @mizzfiend @P3ychxnauT Awesome! Thank you for replying. I am on the right track of it reminds you of dead space.', \"Now Playing:  Bobby Parker &amp; R.A.I.N. - I Don't Know Why @TriceWhitley https://t.co/ycIfY0ibjY #cultivatingmindandspirit\", '@kiana_krystle Just one town over from where I am now in the IE! And omg what days are you in Southern California? We might be able to squeeze something in üëÄ', '#webdevcommunity I‚Äôm in the process of building a mobile app and I am using React- native. I want to set up my navigation but I‚Äôm confused as to whether or not I should use React navigation or expo router? Does anyone have any tips on how to add either to an existing project?', '@amysanrix i am being sarcastic. i‚Äôm not insensitive, i promise.', \"@DarrinBellArt @PublishersWkly Nice!  I am really looking forward to this book!  Been a fan since your second Candorville collection, and it's great to see you stretch out like this.\", '@swifterthings thank you so much, meg üíõ i love you and am so grateful for our friendship :,)', 'I know my rearview can‚Äôt compare to what God will do with my life.   I am forgetting what‚Äôs behind me, I have finally decided. I‚Äôm moving on.', '@StrangestMedia ‚ÄúMove over Jerald! I am trying to get us a sugar daddy.‚Äù üòÇ', 'Hewo, unfortunately I must cancel stream tonight as I have mild food poisoning. \\n\\nI‚Äôm already through the worst of it, but am not really in a state to stream. Tonight‚Äôs anatomy stream will be moved to tomorrow, and Little Nightmares 2 will be bumped to Friday.\\n\\nSee you then!üíû', 'You are not alone. You are seen. I am with you. You are not alone. i love you, ACEs! Andito ako palagi. ü§ç', \"@oleivarrudi Its a tough market, and you're not the only one dev feeling it üòÖ Maybe I am biased but Teslagrad definitely stole the show! https://t.co/okTeWCRFAR\", '‚ÄúMen‚Äù nowadays got documentaries ready for believing Big Sean was up their talkin bout ‚Äúomg you and I am praying upon your', '‚ÄúMen‚Äù nowadays got documentaries ready for believing Big Sean was up their talkin bout ‚Äúomg you and I am praying upon your', 'Am I in a Sacramento Kings group chat?  Yes‚Ä¶.yes I am.', \"So umm... I don't think I need a blue check so people know who I am, semi anonymity is half the fun, but... @Twitter \\nThese are 3 hidden DMs I found trying to contact me.\\nSame sunset, different positions, very different @'s https://t.co/8ibBZv6AhY\", \"@bridgetinapinky True I am here but it's just Inform everyone maybe they will see it have a great day or don't I don't really care üòÅ\", \"it's just the tism and the fact that maybe I am aro üò≠üò≠üò≠üò≠üò≠üò≠\\nqprs r sillyydhdjkf https://t.co/CKNvnWyPN5\", 'I am just now eating for the first time today (I am going to quit this job soon)', 'My family tree holds minutemen, a chief justice of the Supreme Court and framer of the constitution, a civil war general who demanded desegregation, and settlers in the new west. \\n\\nI am descended of incredible Americans.', 'him: do you have some wine? do you think kookoo would this wine? it‚Äôs red \\n\\nme: how am i supposed to know?\\n\\nhim: you know bts. you know what kookoo is doing\\n\\nme: dude i really think he‚Äôs sleeping rn. \\n\\nhim: not fair. when is he talking to you?', \"why is it so hard to lose weight once you're underweight PLEEAASE i am so close to being 45 again and i am not even eating anything that my parents don't force me to https://t.co/Wq81BtnDK2\", 'somebody dye their hair red with me, i am tired of my brown hair again', '@Caleb7414 yes but it was more of a childish hatred \"they are the bad guys and I am the good guy\" the death of Carla raised that x100\\nand the point is what M sees in E\\'s case he doesn\\'t see all the answers becoming a character that at a certain point left a lot of doubts M  is a pawn.', 'Check out my new single \"I Am A Bad Boy\" distributed by @DistroKid and live on Amazon! https://t.co/ldljw5wVXN', 'Genuine question, am I a DUFF?', \"Am I the only person that doesn't like that Peaches song that much? Lol\", '@kittykatkcalss real !!! he can‚Äôt handle how pretty and smart i am /j', 'I\\'m not sure about Spark The Electric Jester getting misconception on every character. Yeah, \"Spark is definitely very emo\" or \"Fark is very ignorant and cares about his powet\"\\n\\nAm I wrong? https://t.co/lz5tuTGhLz', '@Ptxjrpg And this is only part 1 the caption said üò≠ how am I going to survive the actual wedding photos if these are already too much to handle', 'I am, thanks for the permission champ. https://t.co/EEswa0i1bp']\n"
     ]
    }
   ],
   "source": [
    "authenticator = tw.OAuthHandler(api_key, api_secret)\n",
    "authenticator.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(authenticator, wait_on_rate_limit=True)\n",
    "\n",
    "crypto_coin = \"I am\"\n",
    "search_term = f'{crypto_coin} -filter:retweets'\n",
    "\n",
    "tweet_cursor = tw.Cursor(api.search_tweets, q= search_term, lang=\"en\",\n",
    "tweet_mode=\"extended\").items(100)\n",
    "\n",
    "tweets = [tweet.full_text for tweet in tweet_cursor]\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2478b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random = random.randint(0, 90)\n",
    "print(random)\n",
    "test_tweets = tweets[random:random+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2887b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I‚Äôm proud to announce that I - Venusian Prince - did in fact study for his 10 am exam that he will be taking tomorrow. üòå https://t.co/7axPStvj5M\" is a Positive tweet.\n",
      "\n",
      "\"@QueenOfDiagolon Pod bean, and listen in the truck first thing in the am, it gives me that jump start I need in the morning!\" is a Positive tweet.\n",
      "\n",
      "\"@POTUS You are obviously affraid it will be used against you.....I love your support of the seond ammendment.....BTW, when they are banned, you will have no Milatary, but I am sure that does not concern you.  Why not just give more weapons to overseas countries, that will help solve it.\" is a Positive tweet.\n",
      "\n",
      "\"Who pro am team should I join ?\" is a Positive tweet.\n",
      "\n",
      "\"I have accepted the fact that I am not religious.\n",
      "I have accepted the fact that I have much to learn.\n",
      "I have accepted the fact that life fucks all.\n",
      "I have accepted the fact that I am going to hell. \n",
      "I have accepted the fact that people are the worst.\" is a Negative tweet.\n",
      "\n",
      "\"@kxpture I am King üëë\" is a Positive tweet.\n",
      "\n",
      "\"@kevinfolta The fact that you are wasting your time with me is very telling. I am a waste of your time.\" is a Negative tweet.\n",
      "\n",
      "\"Also wanna add I am sick and tired of the main characters knowing each other when they were little kids \n",
      "Like STAPPHHüò≠\" is a Negative tweet.\n",
      "\n",
      "\"@fixbun i am so sorry you have had to experience this you don‚Äôt deserve that invalidation from your mom i‚Äôm here if you need to talk or anything dms are always open.\" is a Negative tweet.\n",
      "\n",
      "\"@CounselorBDavis Yes! I‚Äôm leaving at the end of the year and it is so bittersweet! I love my coworkers (and my kids) but I‚Äôm so burnt out I need a change. But I can‚Äôt even put into words how fortunate I am for these professionals. We are a team and I can‚Äôt imagine having a better one!\" is a Positive tweet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_tweets:\n",
    "    print(predict(i,w2v_cbow, lr_cbow) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
